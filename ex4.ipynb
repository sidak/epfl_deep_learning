{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlc_practical_prologue as prologue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = \\\n",
    "    prologue.load_data(one_hot_labels = True, normalize = True, flatten = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(256, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target = Variable(train_input), Variable(train_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, mini_batch_size, eta=1e-1, \n",
    "                num_epochs=25, criterion=nn.MSELoss()):\n",
    "    for e in range(0, num_epochs):\n",
    "        sum_loss = 0\n",
    "        # We do this with mini-batches\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            sum_loss = sum_loss + loss.data[0]\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            for p in model.parameters():\n",
    "                p.data.sub_(eta * p.grad.data)\n",
    "        print(e, sum_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.938808262348175\n",
      "1 3.8027787804603577\n",
      "2 3.3847336173057556\n",
      "3 2.9938721656799316\n",
      "4 2.632626920938492\n",
      "5 2.696588456630707\n",
      "6 2.39801986515522\n",
      "7 2.2006585597991943\n",
      "8 1.9581044614315033\n",
      "9 1.8174351751804352\n",
      "10 1.6805791854858398\n",
      "11 1.4897380024194717\n",
      "12 1.4427620023488998\n",
      "13 1.3860284313559532\n",
      "14 1.329150602221489\n",
      "15 1.1258902177214622\n",
      "16 1.1413678601384163\n",
      "17 1.048056036233902\n",
      "18 1.0363075882196426\n",
      "19 0.9429718628525734\n",
      "20 0.954571396112442\n",
      "21 0.8853479400277138\n",
      "22 0.7955501079559326\n",
      "23 0.7548313327133656\n",
      "24 0.8152499198913574\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_input, train_target, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input, test_target = Variable(test_input), Variable(test_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pred = model(test_input.narrow(0, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.4376 -0.6748 -0.0570 -0.9269 -1.1562 -1.2176 -0.5933 -1.2256 -0.6457 -1.2463\n",
       "[torch.cuda.FloatTensor of size 1x10 (GPU 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val= tmp_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = tmp_pred==val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    0     0     1     0     0     0     0     0     0     0\n",
       "[torch.cuda.ByteTensor of size 1x10 (GPU 0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = max_idx.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_ans = test_target.narrow(0,1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_batch_ans = test_target.narrow(0,1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "   -1    -1     1    -1    -1    -1    -1    -1    -1    -1\n",
       "   -1     1    -1    -1    -1    -1    -1    -1    -1    -1\n",
       "    1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
       "   -1    -1    -1    -1     1    -1    -1    -1    -1    -1\n",
       "   -1     1    -1    -1    -1    -1    -1    -1    -1    -1\n",
       "   -1    -1    -1    -1     1    -1    -1    -1    -1    -1\n",
       "   -1    -1    -1    -1    -1    -1    -1    -1    -1     1\n",
       "   -1    -1    -1    -1    -1     1    -1    -1    -1    -1\n",
       "   -1    -1    -1    -1    -1    -1    -1    -1    -1     1\n",
       "    1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
       "   -1    -1    -1    -1    -1    -1     1    -1    -1    -1\n",
       "   -1    -1    -1    -1    -1    -1    -1    -1    -1     1\n",
       "    1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
       "   -1     1    -1    -1    -1    -1    -1    -1    -1    -1\n",
       "   -1    -1    -1    -1    -1     1    -1    -1    -1    -1\n",
       "   -1    -1    -1    -1    -1    -1    -1    -1    -1     1\n",
       "   -1    -1    -1    -1    -1    -1    -1     1    -1    -1\n",
       "   -1    -1    -1     1    -1    -1    -1    -1    -1    -1\n",
       "   -1    -1    -1    -1     1    -1    -1    -1    -1    -1\n",
       "   -1    -1    -1    -1    -1    -1    -1    -1    -1     1\n",
       "   -1    -1    -1    -1    -1    -1     1    -1    -1    -1\n",
       "   -1    -1    -1    -1    -1    -1     1    -1    -1    -1\n",
       "   -1    -1    -1    -1    -1     1    -1    -1    -1    -1\n",
       "   -1    -1    -1    -1     1    -1    -1    -1    -1    -1\n",
       "    1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
       "   -1    -1    -1    -1    -1    -1    -1     1    -1    -1\n",
       "   -1    -1    -1    -1     1    -1    -1    -1    -1    -1\n",
       "    1    -1    -1    -1    -1    -1    -1    -1    -1    -1\n",
       "   -1     1    -1    -1    -1    -1    -1    -1    -1    -1\n",
       "   -1    -1    -1     1    -1    -1    -1    -1    -1    -1\n",
       "[torch.cuda.FloatTensor of size 30x10 (GPU 0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_batch_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_batch_pred = model(test_input.narrow(0, 1, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.4376 -0.6748 -0.0570 -0.9269 -1.1562 -1.2176 -0.5933 -1.2256 -0.6457 -1.2463\n",
       "-0.8897  0.7963 -1.0881 -0.8873 -0.8911 -0.9727 -0.9410 -0.7041 -0.9054 -1.0263\n",
       " 0.8021 -1.1225 -1.2650 -0.9816 -1.0224 -1.3251 -0.7535 -0.7151 -1.0444 -0.8582\n",
       "-1.0378 -0.8712 -1.1804 -0.9227  0.7460 -1.2810 -0.8172 -0.5629 -0.9938 -0.9377\n",
       "-0.9154  0.8726 -1.2129 -0.9611 -1.0083 -1.2355 -1.0351 -0.6877 -0.9813 -0.9960\n",
       "-1.2860 -0.8813 -1.2562 -0.8147  0.3782 -1.4103 -0.8804 -0.5972 -0.6416 -0.9620\n",
       "-0.9324 -0.9687 -0.8900 -0.8830 -0.6821 -1.0232 -0.7809 -0.6995 -0.5379 -0.1058\n",
       "-0.9662 -1.0657 -0.3847 -1.3716 -0.7667 -0.2075 -0.5186 -0.8074 -0.7190 -0.7214\n",
       "-0.9722 -1.1895 -1.1869 -0.8815 -0.7913 -1.3692 -0.9676 -0.3487 -0.4993  0.2223\n",
       " 0.7219 -1.0087 -0.9736 -1.0727 -0.8711 -1.0938 -0.9293 -0.9840 -0.6630 -1.0484\n",
       "-0.4819 -1.2164 -1.2290 -0.8915 -0.6528 -1.1434  0.2278 -1.0230 -0.2944 -0.9053\n",
       "-0.7830 -1.1018 -1.0193 -1.0171 -0.6045 -1.2747 -1.0809 -0.7769 -0.9118  0.6018\n",
       " 1.0382 -0.9740 -1.1943 -1.0563 -1.0248 -1.3093 -1.0338 -0.9251 -0.6356 -0.8877\n",
       "-0.9760  0.6601 -1.0910 -0.8686 -0.9673 -1.2099 -1.0253 -0.8025 -0.8522 -1.1318\n",
       "-0.7674 -0.8625 -0.9215 -0.3410 -0.7166 -0.2721 -0.6885 -0.7871 -0.5350 -1.1875\n",
       "-0.8559 -1.0649 -1.1597 -1.0207 -0.5067 -1.4229 -0.9773 -0.1810 -0.8450 -0.0710\n",
       "-0.9163 -1.0129 -1.1066 -0.8900 -1.0623 -1.2329 -0.8722  1.1339 -0.9763 -1.1968\n",
       "-1.0095 -1.1143 -0.8729 -0.1577 -0.6968 -0.5903 -0.9125 -0.7715 -0.4057 -0.8931\n",
       "-1.0653 -0.8784 -1.1320 -0.8858  0.6713 -1.1612 -0.9487 -0.9547 -0.9017 -0.6937\n",
       "-1.0345 -1.0701 -1.1991 -0.8350 -0.7408 -1.3283 -1.0512 -0.2748 -0.8622  0.1552\n",
       "-1.1020 -1.1578 -1.3469 -1.0895 -0.7568 -0.6001  0.6565 -0.9152 -0.5370 -1.4103\n",
       "-0.8183 -1.0371 -1.3175 -0.9768 -0.1147 -1.2073  0.0300 -0.9969 -0.7033 -0.9801\n",
       "-0.7454 -1.0942 -0.9879 -0.7614 -0.9275  0.3248 -0.4272 -0.9546 -0.6458 -0.9426\n",
       "-1.0254 -0.7784 -0.8640 -0.7089  0.2492 -0.8897 -0.5910 -0.5937 -0.8642 -0.5896\n",
       " 0.9150 -1.2353 -0.9896 -1.2793 -0.8456 -1.2403 -0.8008 -1.0325 -0.4570 -1.0035\n",
       "-0.9135 -0.8088 -1.0427 -0.7738 -1.0654 -1.0955 -0.8224  0.8508 -0.8767 -0.8286\n",
       "-1.0656 -1.0403 -1.1810 -0.9550  0.7806 -1.1556 -0.8740 -0.9995 -1.0341 -0.6117\n",
       " 0.9092 -1.0216 -1.0862 -0.8225 -1.0305 -1.2693 -1.1181 -1.0620 -0.6981 -1.0694\n",
       "-0.9735  0.3514 -1.0005 -0.8373 -0.7478 -1.0565 -0.9303 -0.8871 -0.5876 -0.9792\n",
       "-0.9813 -1.0196 -1.2578  0.8221 -0.9558 -0.9400 -0.8968 -0.6538 -0.9100 -0.9691\n",
       "[torch.cuda.FloatTensor of size 30x10 (GPU 0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_batch_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2\n",
       " 1\n",
       " 0\n",
       " 4\n",
       " 1\n",
       " 4\n",
       " 9\n",
       " 5\n",
       " 9\n",
       " 0\n",
       " 6\n",
       " 9\n",
       " 0\n",
       " 1\n",
       " 5\n",
       " 9\n",
       " 7\n",
       " 3\n",
       " 4\n",
       " 9\n",
       " 6\n",
       " 6\n",
       " 5\n",
       " 4\n",
       " 0\n",
       " 7\n",
       " 4\n",
       " 0\n",
       " 1\n",
       " 3\n",
       "[torch.cuda.LongTensor of size 30 (GPU 0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_batch_pred.max(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       " [torch.cuda.FloatTensor of size 30 (GPU 0)], Variable containing:\n",
       "  2\n",
       "  1\n",
       "  0\n",
       "  4\n",
       "  1\n",
       "  4\n",
       "  9\n",
       "  5\n",
       "  9\n",
       "  0\n",
       "  6\n",
       "  9\n",
       "  0\n",
       "  1\n",
       "  5\n",
       "  9\n",
       "  7\n",
       "  3\n",
       "  4\n",
       "  9\n",
       "  6\n",
       "  6\n",
       "  5\n",
       "  4\n",
       "  0\n",
       "  7\n",
       "  4\n",
       "  0\n",
       "  1\n",
       "  3\n",
       " [torch.cuda.LongTensor of size 30 (GPU 0)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_batch_ans.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2\n",
       " 1\n",
       " 0\n",
       " 4\n",
       " 1\n",
       " 4\n",
       " 9\n",
       " 5\n",
       " 9\n",
       " 0\n",
       " 6\n",
       " 9\n",
       " 0\n",
       " 1\n",
       " 5\n",
       " 9\n",
       " 7\n",
       " 3\n",
       " 4\n",
       " 9\n",
       " 6\n",
       " 6\n",
       " 5\n",
       " 4\n",
       " 0\n",
       " 7\n",
       " 4\n",
       " 0\n",
       " 1\n",
       " 3\n",
       "[torch.cuda.LongTensor of size 30 (GPU 0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_batch_ans.max(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2\n",
       " 1\n",
       " 0\n",
       " 4\n",
       " 1\n",
       " 4\n",
       " 9\n",
       " 5\n",
       " 9\n",
       " 0\n",
       " 6\n",
       " 9\n",
       " 0\n",
       " 1\n",
       " 5\n",
       " 9\n",
       " 7\n",
       " 3\n",
       " 4\n",
       " 9\n",
       " 6\n",
       " 6\n",
       " 5\n",
       " 4\n",
       " 0\n",
       " 7\n",
       " 4\n",
       " 0\n",
       " 1\n",
       " 3\n",
       "[torch.cuda.LongTensor of size 30 (GPU 0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_batch_pred.max(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tmp_batch_ans.max(1)[1] != tmp_batch_pred.max(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       "[torch.cuda.ByteTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sum().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "   -1    -1     1    -1    -1    -1    -1    -1    -1    -1\n",
       "[torch.cuda.FloatTensor of size 1x10 (GPU 0)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, test_input, test_target, mini_batch_size):\n",
    "    nb_error = 0.0\n",
    "    for b in range(0, test_input.size(0), mini_batch_size):\n",
    "        test_output = model(test_input.narrow(0, b, mini_batch_size))\n",
    "        test_ans = test_target.narrow(0, b, mini_batch_size)\n",
    "        output_max_idx = test_output.max(1)[1]\n",
    "        ans_max_idx = test_ans.max(1)[1]\n",
    "        nb_error +=  (output_max_idx!=ans_max_idx).sum()\n",
    "    return nb_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 96\n",
       "[torch.cuda.ByteTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nb_errors(model, test_input, test_target, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
